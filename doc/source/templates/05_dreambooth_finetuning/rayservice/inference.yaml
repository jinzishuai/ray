apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: dreambooth-inference
  namespace: ray-gpu
spec:
  serveConfigV2: |
    applications:
      - name: original_stable_diffusion
        route_prefix: /original
        import_path: doc.source.templates.05_dreambooth_finetuning.rayservice.stable_diffusion:entrypoint
        runtime_env:
          working_dir: "https://github.com/jinzishuai/ray/archive/master.zip"
          env_var:
            - name: MODEL_PATH
              value: "/data/tmp/model-orig/models--CompVis--stable-diffusion-v1-4/snapshots/b95be7d6f134c3a9e62ee616f310733567f069ce"
        # deployments:
        #   - name: APIIngress
        #     ray_actor_options:
        #       num_cpus: 0.1          
      - name: tuned_dreambooth
        route_prefix: /tuned
        import_path: doc.source.templates.05_dreambooth_finetuning.rayservice.stable_diffusion:entrypoint
        runtime_env:
          working_dir: "https://github.com/jinzishuai/ray/archive/master.zip"
          env_var:
            - name: MODEL_PATH
              value: "/data/tmp/model-tuned"
        # deployments:
        #   - name: APIIngress
        #     ray_actor_options:
        #       num_cpus: 0.1
  serviceUnhealthySecondThreshold: 600
  deploymentUnhealthySecondThreshold: 600
  rayClusterConfig:
    rayVersion: "2.8.1"
    enableInTreeAutoscaling: true
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
        # Setting "num-cpus: 0" to avoid any Ray actors or tasks being scheduled on the Ray head Pod.
        num-cpus: "0"
      template:
        spec:
          containers:
            - name: ray-head
              image: jinzishuai/ray-train-dreambooth:2.8.1-py310-gpu-arrow13
              resources:
                limits:
                  cpu: 2 # 4 CPUs requires g5.2xlarge., 3 CPUs fits in g5.xlarge
                  memory: 4Gi
                  nvidia.com/gpu: 0
                requests:
                  cpu: 2
                  memory: 4Gi
                  nvidia.com/gpu: 0 # 1 fits within a g5.xlarge instance in AWS
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
              volumeMounts:
                - name: persistent-storage
                  mountPath: /data
          volumes:
            - name: persistent-storage
              persistentVolumeClaim:
                claimName: efs-claim
    workerGroupSpecs:
      - replicas: 0 # having two nodes would already require a g5.12xlarge instance (with 4 GPUs)
        minReplicas: 0
        maxReplicas: 0
        rayStartParams: {}
        groupName: gpu-group
        template:
          spec:
            containers:
              - name: ray-worker
                image: jinzishuai/ray-train-dreambooth:2.8.1-py310-gpu-arrow13
                resources:
                  limits:
                    cpu: "3" # 4 CPUs requires g5.2xlarge., 3 CPUs fits in g5.xlarge
                    memory: "13Gi" # 13GB fits in g5.xlarge
                    nvidia.com/gpu: 1 # 1 fits within a g5.xlarge instance in AWS
                  requests:
                    cpu: "3"
                    memory: "13Gi"
                    nvidia.com/gpu: 1
                volumeMounts:
                  - name: persistent-storage
                    mountPath: /data
            volumes:
              - name: persistent-storage
                persistentVolumeClaim:
                  claimName: efs-claim
      - replicas: 1 # having two nodes would already require a g5.12xlarge instance (with 4 GPUs)
        minReplicas: 1
        maxReplicas: 1
        rayStartParams:
          num-cpus: "3" # overrite to tell Ray there are 2 logical CPUs per node instead of the requested 1 from k8s
        groupName: cpu-group
        template:
          spec:
            containers:
              - name: ray-worker
                image: jinzishuai/ray-train-dreambooth:2.8.1-py310-gpu-arrow13
                resources:
                  limits:
                    cpu: 1
                    memory: "4Gi"
                    nvidia.com/gpu: 0
                  requests:
                    cpu: 1
                    memory: "4Gi"
                    nvidia.com/gpu: 0
                volumeMounts:
                  - name: persistent-storage
                    mountPath: /data
            volumes:
              - name: persistent-storage
                persistentVolumeClaim:
                  claimName: efs-claim
# ---
# apiVersion: networking.k8s.io/v1
# kind: Ingress
# metadata:
#   name: ray-training
#   namespace: ray-training
#   annotations:
#     nginx.ingress.kubernetes.io/rewrite-target: "/$1"
# spec:
#   ingressClassName: nginx
#   rules:
#     - http:
#         paths:
#           # Ray Dashboard
#           - path: /ray-training/(.*)
#             pathType: ImplementationSpecific
#             backend:
#               service:
#                 name: ray-training-head-svc
#                 port:
#                   number: 8265
