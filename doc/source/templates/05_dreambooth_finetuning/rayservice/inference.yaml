apiVersion: ray.io/v1alpha1
kind: RayService
metadata:
  name: dreambooth-inference
  namespace: ray-gpu
spec:
  serveConfigV2: |
    applications:
      - name: original_stable_diffusion
        route_prefix: /original
        import_path: doc.source.templates.05_dreambooth_finetuning.rayservice.stable_diffusion:entrypoint
        runtime_env:
          working_dir: "https://github.com/jinzishuai/ray/archive/master.zip"
          env_var:
            - name: MODEL_PATH
              value: "/data/tmp/model-orig/models--CompVis--stable-diffusion-v1-4/snapshots/b95be7d6f134c3a9e62ee616f310733567f069ce"
      - name: tuned_dreambooth
        route_prefix: /tuned
        import_path: doc.source.templates.05_dreambooth_finetuning.rayservice.stable_diffusion:entrypoint
        runtime_env:
          working_dir: "https://github.com/jinzishuai/ray/archive/master.zip"
          env_var:
            - name: MODEL_PATH
              value: "/data/tmp/model-tuned"
  serviceUnhealthySecondThreshold: 600
  deploymentUnhealthySecondThreshold: 600
  rayClusterConfig:
    rayVersion: "2.8.1"
    enableInTreeAutoscaling: true
    headGroupSpec:
      rayStartParams:
        dashboard-host: "0.0.0.0"
      template:
        spec:
          containers:
            - name: ray-head
              image: jinzishuai/ray-train-dreambooth:2.8.1-py310-gpu-arrow13
              resources:
                limits:
                  cpu: 3 # 4 CPUs requires g5.2xlarge., 3 CPUs fits in g5.xlarge
                  memory: 13Gi
                  nvidia.com/gpu: 1
                requests:
                  cpu: 3
                  memory: 13Gi
                  nvidia.com/gpu: 1 # fits within a g5.xlarge instance in AWS
              ports:
                - containerPort: 6379
                  name: gcs-server
                - containerPort: 8265
                  name: dashboard
                - containerPort: 10001
                  name: client
                - containerPort: 8000
                  name: serve
              volumeMounts:
                - name: persistent-storage
                  mountPath: /data
          volumes:
            - name: persistent-storage
              persistentVolumeClaim:
                claimName: efs-claim
    workerGroupSpecs:
      - replicas: 0 # having two nodes would already require a g5.12xlarge instance (with 4 GPUs)
        minReplicas: 0
        maxReplicas: 3
        rayStartParams: {}
        groupName: small-group
        template:
          spec:
            containers:
              - name: ray-worker
                image: jinzishuai/ray-train-dreambooth:2.8.1-py310-gpu-arrow13
                resources:
                  limits:
                    cpu: "3"
                    memory: "13Gi"
                    nvidia.com/gpu: 1
                  requests:
                    cpu: "3"
                    memory: "13Gi"
                    nvidia.com/gpu: 1
                volumeMounts:
                  - name: persistent-storage
                    mountPath: /data
            volumes:
              - name: persistent-storage
                persistentVolumeClaim:
                  claimName: efs-claim
# ---
# apiVersion: networking.k8s.io/v1
# kind: Ingress
# metadata:
#   name: ray-training
#   namespace: ray-training
#   annotations:
#     nginx.ingress.kubernetes.io/rewrite-target: "/$1"
# spec:
#   ingressClassName: nginx
#   rules:
#     - http:
#         paths:
#           # Ray Dashboard
#           - path: /ray-training/(.*)
#             pathType: ImplementationSpecific
#             backend:
#               service:
#                 name: ray-training-head-svc
#                 port:
#                   number: 8265
